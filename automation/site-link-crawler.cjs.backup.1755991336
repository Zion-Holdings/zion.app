#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
<<<<<<< HEAD

const ROOT = process.cwd();
const PAGES_DIR = path.join(ROOT, 'pages');
const REPORT_JSON_DIR = path.join(ROOT, 'data', 'reports', 'internal-links');
const REPORT_HTML_DIR = path.join(ROOT, 'public', 'reports', 'links');

function ensureDir(dirPath) {
  fs.mkdirSync(dirPath, { recursive: true });
}

function* walkFiles(startDir, exts = ['.tsx', '.ts', '.jsx', '.js', '.mdx']) {
  if (!fs.existsSync(startDir)) return;
  const stack = [startDir];
  while (stack.length) {
    const current = stack.pop();
    let entries = [];
    try { entries = fs.readdirSync(current, { withFileTypes: true }); } catch { continue; }
    for (const entry of entries) {
      const full = path.join(current, entry.name);
      if (entry.isDirectory()) {
        if (entry.name === 'api' || entry.name === 'node_modules' || entry.name.startsWith('.')) continue;
        stack.push(full);
      } else if (entry.isFile()) {
        if (exts.includes(path.extname(entry.name))) yield full;
      }
    }
  }
}

function getRoutes(dir, base = '') {
  if (!fs.existsSync(dir)) return [];
  const entries = fs.readdirSync(dir, { withFileTypes: true });
  const routes = [];
  for (const e of entries) {
    if (e.name.startsWith('_')) continue; // skip Next internals
    if (e.isDirectory()) {
      if (e.name === 'api') continue;
      routes.push(...getRoutes(path.join(dir, e.name), base + '/' + e.name));
    } else if (e.isFile()) {
      if (!e.name.match(/\.(tsx|jsx|mdx|js|ts)$/)) continue;
      const name = e.name.replace(/\.(tsx|jsx|mdx|js|ts)$/, '');
      if (name === 'index') {
        routes.push(base || '/');
      } else if (!name.startsWith('[')) {
        routes.push(base + '/' + name);
      }
    }
  }
  return Array.from(new Set(routes)).sort();
}

function extractInternalLinks(text) {
  const links = new Set();
  // Match href="/path" or href={'/path'} or Link href="/path"
  const regex = /href\s*=\s*{?\s*["'`](\/[\w\-\/\.]*)(?:#[^"'`}]*)?["'`}\)]/g;
  let m;
  while ((m = regex.exec(text)) !== null) {
    const url = m[1];
    if (!url) continue;
    if (url.startsWith('//')) continue; // protocol-relative external
    if (url.startsWith('/api')) continue; // ignore API routes
    if (url.startsWith('/_next')) continue; // ignore Next internals
    links.add(url.replace(/\/$/, '') || '/');
  }
  return Array.from(links);
}

function readFileSafe(file) {
  try { return fs.readFileSync(file, 'utf8'); } catch { return ''; }
}

function discoverRedirectMap() {
  // Simple static discovery from next.config.js known redirects
  const configPath = path.join(ROOT, 'next.config.js');
  const map = new Map();
  const text = readFileSafe(configPath);
  // Look for patterns like { source: '/front', destination: '/', permanent: true }
  const re = /source:\s*['"]([^'"]+)['"],\s*destination:\s*['"]([^'"]+)['"]/g;
  let m;
  while ((m = re.exec(text)) !== null) {
    map.set(m[1], m[2]);
  }
  return map;
}

function renderHtmlReport(results) {
  const rows = results.map(r => `
      <tr>
        <td>${r.file.replace(ROOT + '/', '')}</td>
        <td>${r.link}</td>
        <td>${r.status}</td>
        <td>${r.suggestion || ''}</td>
      </tr>`).join('\n');
  return `<!DOCTYPE html>
<html><head><meta charset="utf-8"/><title>Internal Link Report</title>
<style>
body{font-family:system-ui,Segoe UI,Roboto,Inter,sans-serif;margin:24px}
 table{border-collapse:collapse;width:100%}
 th,td{border:1px solid #ddd;padding:8px;font-size:14px}
 th{background:#f3f4f6;text-align:left}
 .ok{color:#065f46}
 .bad{color:#991b1b}
</style></head>
<body>
  <h1>Internal Link Report</h1>
  <p>Validated internal links found in pages. Broken links include a suggestion when a redirect is known.</p>
  <table>
    <thead><tr><th>File</th><th>Link</th><th>Status</th><th>Suggestion</th></tr></thead>
    <tbody>
${rows || '<tr><td colspan="4">No issues found.</td></tr>'}
    </tbody>
  </table>
</body></html>`;
}

async function main() {
  const validRoutes = new Set(getRoutes(PAGES_DIR).map(r => (r === '' ? '/' : r)));
  // Normalize: include root without trailing slash
  const normalizedRoutes = new Set(Array.from(validRoutes, r => r === '/' ? '/' : r.replace(/\/$/, '')));
  const redirectMap = discoverRedirectMap();

  const issues = [];
  const scanned = [];

  for (const file of walkFiles(PAGES_DIR)) {
    const text = readFileSafe(file);
    if (!text) continue;
    const links = extractInternalLinks(text);
    if (!links.length) continue;
    for (const link of links) {
      const normalizedLink = link === '/' ? '/' : link.replace(/\/$/, '');
      let status = 'ok';
      let suggestion = null;
      if (!normalizedRoutes.has(normalizedLink)) {
        status = 'missing';
        // try redirect map
        if (redirectMap.has(normalizedLink)) {
          suggestion = redirectMap.get(normalizedLink);
        } else if (redirectMap.has(normalizedLink.replace(/\/$/, ''))) {
          suggestion = redirectMap.get(normalizedLink.replace(/\/$/, ''));
        }
        issues.push({ file, link: normalizedLink, status, suggestion });
      }
      scanned.push({ file, link: normalizedLink, status, suggestion });
    }
  }
=======
const urlLib = require('url');
const axios = require('axios');
const cheerio = require('cheerio');

const REPORT_JSON_DIR = path.join(process.cwd(), 'data', 'reports', 'link-integrity');
const REPORT_HTML_DIR = path.join(process.cwd(), 'public', 'reports', 'links');

function ensureDir(p) {
  fs.mkdirSync(p, { recursive: true });
}

function normalizeUrl(baseUrl, href) {
  if (!href) return null;
  const trimmed = href.trim();
  if (!trimmed || trimmed.startsWith('mailto:') || trimmed.startsWith('tel:') || trimmed.startsWith('javascript:')) return null;
  // ignore pure hash links
  if (trimmed.startsWith('#')) return null;
  try {
    const u = new urlLib.URL(trimmed, baseUrl);
    // Remove hash for canonical link checks
    u.hash = '';
    return u.toString();
  } catch {
    return null;
  }
}

function isSameOrigin(a, b) {
  try {
    const ua = new urlLib.URL(a);
    const ub = new urlLib.URL(b);
    return ua.origin === ub.origin;
  } catch {
    return false;
  }
}

async function fetchPage(url, timeoutMs = 15000) {
  try {
    const res = await axios.get(url, { timeout: timeoutMs, maxRedirects: 5, validateStatus: () => true, headers: { 'User-Agent': 'SiteLinkCrawler/1.0' } });
    return { status: res.status, html: res.data, ok: res.status >= 200 && res.status < 400 };
  } catch (e) {
    return { status: 0, html: '', ok: false, error: e.message };
  }
}

function extractLinks(baseUrl, html) {
  const $ = cheerio.load(html || '');
  const links = new Set();
  $('a[href]').each((_, el) => {
    const href = $(el).attr('href');
    const absolute = normalizeUrl(baseUrl, href);
    if (absolute && isSameOrigin(baseUrl, absolute)) {
      links.add(absolute);
    }
  });
  // Also capture links in Next.js Link with child anchor-less patterns (rare)
  $('[href]').each((_, el) => {
    const href = $(el).attr('href');
    const absolute = normalizeUrl(baseUrl, href);
    if (absolute && isSameOrigin(baseUrl, absolute)) {
      links.add(absolute);
    }
  });
  return Array.from(links);
}

async function headOrGet(url) {
  try {
    const res = await axios.head(url, { timeout: 10000, maxRedirects: 5, validateStatus: () => true });
    return { status: res.status, ok: res.status >= 200 && res.status < 400 };
  } catch {
    try {
      const res2 = await axios.get(url, { timeout: 15000, maxRedirects: 5, validateStatus: () => true });
      return { status: res2.status, ok: res2.status >= 200 && res2.status < 400 };
    } catch (e2) {
      return { status: 0, ok: false, error: e2.message };
    }
  }
}

async function crawl({ baseUrl, maxPages = 500 }) {
  const toVisit = [baseUrl];
  const visited = new Set();
  const pages = [];
  const brokenLinks = [];

  while (toVisit.length && visited.size < maxPages) {
    const current = toVisit.shift();
    if (!current || visited.has(current)) continue;
    visited.add(current);

    const pageRes = await fetchPage(current);
    const links = pageRes.ok ? extractLinks(current, pageRes.html) : [];

    pages.push({ url: current, status: pageRes.status, linkCount: links.length, ok: pageRes.ok });

    for (const l of links) {
      // only enqueue same-origin new pages
      if (!visited.has(l) && isSameOrigin(baseUrl, l)) {
        toVisit.push(l);
      }
    }

    // Check links on this page
    const checks = await Promise.all(links.map((l) => headOrGet(l).then((r) => ({ href: l, ...r }))));
    for (const res of checks) {
      if (!res.ok) brokenLinks.push({ from: current, href: res.href, status: res.status, error: res.error || null });
    }
  }

  // De-duplicate broken entries (same from+href)
  const uniqMap = new Map();
  for (const b of brokenLinks) {
    const key = `${b.from} -> ${b.href}`;
    if (!uniqMap.has(key)) uniqMap.set(key, b);
  }

  return {
    baseUrl,
    generatedAt: new Date().toISOString(),
    pagesScanned: pages.length,
    linksChecked: pages.reduce((sum, p) => sum + (p.linkCount || 0), 0),
    broken: Array.from(uniqMap.values()),
    pages,
  };
}

function renderHtmlReport(report) {
  const rows = report.broken.map((b) => `
    <tr>
      <td><a href="${b.from}" target="_blank" rel="noopener">${b.from}</a></td>
      <td><code>${b.status}</code></td>
      <td><a href="${b.href}" target="_blank" rel="noopener">${b.href}</a></td>
      <td>${b.error ? b.error.replace(/</g,'&lt;') : ''}</td>
    </tr>`).join('\n');
  return `<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Link Integrity Report</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Inter, sans-serif; margin: 24px; }
    table { border-collapse: collapse; width: 100%; }
    th, td { border: 1px solid #e5e7eb; padding: 8px; font-size: 14px; }
    th { background: #f3f4f6; text-align: left; }
    code { background: #f3f4f6; padding: 1px 4px; border-radius: 4px; }
  </style>
</head>
<body>
  <h1>Link Integrity Report</h1>
  <p><strong>Base:</strong> ${report.baseUrl} &nbsp; • &nbsp; <strong>Generated:</strong> ${report.generatedAt}</p>
  <p><strong>Pages scanned:</strong> ${report.pagesScanned} &nbsp; • &nbsp; <strong>Links checked:</strong> ${report.linksChecked} &nbsp; • &nbsp; <strong>Broken:</strong> ${report.broken.length}</p>
  <table>
    <thead>
      <tr><th>From page</th><th>Status</th><th>Broken link</th><th>Error</th></tr>
    </thead>
    <tbody>
      ${rows || '<tr><td colspan="4">No issues found.</td></tr>'}
    </tbody>
  </table>
</body>
</html>`;
}

async function main() {
  const defaultBase = process.env.SITE_BASE_URL || process.env.SITEMAP_BASE_URL || process.env.DEPLOY_PRIME_URL || process.env.URL || 'https://zion.app';
  const baseUrl = (process.argv[2] && process.argv[2].startsWith('http')) ? process.argv[2] : defaultBase;
>>>>>>> origin/cursor/crawl-and-fix-site-links-and-pages-ed4d

  ensureDir(REPORT_JSON_DIR);
  ensureDir(REPORT_HTML_DIR);

<<<<<<< HEAD
  const payload = {
    generatedAt: new Date().toISOString(),
    totalLinks: scanned.length,
    broken: issues.length,
    issues,
  };

  fs.writeFileSync(path.join(REPORT_JSON_DIR, `internal-links-${Date.now()}.json`), JSON.stringify(payload, null, 2));
  fs.writeFileSync(path.join(REPORT_JSON_DIR, `latest.json`), JSON.stringify(payload, null, 2));

  const html = renderHtmlReport(issues);
  fs.writeFileSync(path.join(REPORT_HTML_DIR, 'index.html'), html);

  console.log(`Internal link crawl complete. Scanned: ${scanned.length}. Broken: ${issues.length}.`);
}

main().catch((e) => { console.error(e); process.exit(1); });
=======
  const report = await crawl({ baseUrl, maxPages: Number(process.env.LINK_CRAWL_MAX || 500) });

  const jsonPath = path.join(REPORT_JSON_DIR, 'latest.json');
  const htmlPath = path.join(REPORT_HTML_DIR, 'index.html');

  fs.writeFileSync(jsonPath, JSON.stringify(report, null, 2));
  fs.writeFileSync(path.join(REPORT_JSON_DIR, `report-${Date.now()}.json`), JSON.stringify(report, null, 2));
  fs.writeFileSync(htmlPath, renderHtmlReport(report));

  console.log(`Link crawl complete. Pages: ${report.pagesScanned}. Broken: ${report.broken.length}.`);
  console.log(`JSON: ${jsonPath}`);
  console.log(`HTML: ${htmlPath}`);
}

if (require.main === module) {
  main().catch((e) => { console.error(e); process.exit(1); });
}
>>>>>>> origin/cursor/crawl-and-fix-site-links-and-pages-ed4d
