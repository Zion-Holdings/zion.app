#!/usr/bin/env node

/**
 * Comprehensive Redundancy System
 * Provides complete backup automation for all systems:
 * - PM2 automations
 * - GitHub Actions automations  
 * - Netlify functions automations
 */

const { execSync, spawn } = require('child_process');
const fs = require('fs');
const path = require('path');

class ComprehensiveRedundancySystem {
  constructor() {
    this.config = {
      pm2: {
        ecosystemFiles: [
          'ecosystem.pm2.cjs',
          'ecosystem-redundancy.pm2.cjs',
          'ecosystem.redundancy.cjs'
        ],
        processes: [
          'zion-auto-sync',
          'zion-auto-sync-cron',
          'zion-auto-sync-backup',
          'zion-auto-sync-cron-backup',
          'redundancy-master-orchestrator',
          'redundancy-pm2-manager',
          'redundancy-github-manager',
          'redundancy-netlify-manager',
          'build-monitor-backup',
          'git-sync-backup',
          'netlify-healer-backup'
        ]
      },
      github: {
        workflows: [
          'marketing-sync.yml',
          'sync-health.yml',
          'marketing-sync-backup.yml',
          'sync-health-backup.yml'
        ],
        schedules: {
          'marketing-sync': '0 */12 * * *',
          'sync-health': '*/15 * * * *',
          'marketing-sync-backup': '30 */12 * * *',
          'sync-health-backup': '*/20 * * * *'
        }
      },
      netlify: {
        functions: [
          'a11y-alt-text-runner',
          'adaptive-orchestrator',
          'ai-changelog-runner',
          'ai-trends-radar-runner',
          'anchor-links-auto-fixer',
          'auto-discovery-runner',
          'auto-scheduler',
          'automation-matrix',
          'autonomous-invention-orchestrator',
          'autonomous-meta-orchestrator',
          'broken-image-scanner',
          'broken-image-scanner-runner',
          'canonical-auditor',
          'cloud_deep_research',
          'cloud_orchestrator',
          'code-smell-audit-runner',
          'component-coupling-graph-runner',
          'component-props-docs-runner',
          'component-size-report',
          'content-freshness-score-runner',
          'continuous-front-runner',
          'continuous-orchestrator',
          'dead-code-audit',
          'dead-code-report',
          'deps-auto-upgrade-runner',
          'docs-index-runner',
          'docs-search-index-runner',
          'duplicate-media-finder-runner',
          'external-link-check-runner',
          'fast-front-promoter',
          'fast-orchestrator',
          'feature-advertiser',
          'features-capabilities-benefits-advertiser',
          'front-ads-promoter',
          'front-enhancer',
          'front-index-futurizer',
          'front-index-orchestrator',
          'front-index-scheduler',
          'front-maximizer',
          'front-visionary-expander',
          'frontpage-enhancer',
          'frontpage-scheduler',
          'headers-enforcer',
          'home-visionary-expander',
          'homepage-advertiser-scheduler',
          'homepage-enhancer',
          'homepage-updater',
          'homepage-updater-scheduler',
          'homepage_advertiser',
          'hyper-front-index-accelerator',
          'image-optimizer-runner',
          'innovation-lab',
          'innovations-promoter',
          'intelligent-meta-orchestrator',
          'internal-link-graph-runner',
          'knowledge-pack-runner',
          'license-compliance-auditor',
          'link-and-health-scheduler',
          'link-crawler',
          'maintenance-scheduler',
          'marketing-and-features-promo',
          'marketing-scheduler',
          'media-og-and-optimize',
          'metadata-optimizer-runner',
          'netlify-auto-healer-runner',
          'newsroom-auto-publisher',
          'newsroom-runner',
          'og-image-update-runner',
          'orphan-pages-detector',
          'pagespeed-insights-runner',
          'readme-advertiser',
          'repo-knowledge-graph-runner',
          'repo-radar-and-graph',
          'repo-radar-runner',
          'revenue-ideas-lab',
          'roadmap-curator',
          'robots-auditor',
          'schedule-content-index',
          'schedule-homepage',
          'schedule-knowledge-graph',
          'schedule-site-health',
          'security-audit',
          'security-audit-runner',
          'seo-audit-runner',
          'site-404-map-runner',
          'site-crawler',
          'sitemap_runner',
          'stale-content-auditor-runner',
          'todo-scanner-runner',
          'todo-summary-runner',
          'topic-cluster-builder-runner',
          'topics-map-runner',
          'trigger-all-and-commit',
          'ui-enhancer',
          'ultrafast-front-orchestrator',
          'ultrafast-orchestrator',
          'unused-media-scanner'
        ]
      }
    };
    
    this.status = {
      pm2: { running: false, processes: [] },
      github: { workflows: [], lastRun: null },
      netlify: { functions: [], lastDeploy: null }
    };
  }

  async start() {
    console.log('ðŸš€ Starting Comprehensive Redundancy System...');
    
    try {
      // Start PM2 redundancy
      await this.startPM2Redundancy();
      
      // Start GitHub Actions redundancy
      await this.startGitHubActionsRedundancy();
      
      // Start Netlify Functions redundancy
      await this.startNetlifyFunctionsRedundancy();
      
      // Start monitoring
      this.startMonitoring();
      
      console.log('âœ… Comprehensive Redundancy System started successfully');
    } catch (error) {
      console.error('âŒ Failed to start Comprehensive Redundancy System:', error);
      throw error;
    }
  }

  async startPM2Redundancy() {
    console.log('ðŸ“± Starting PM2 Redundancy...');
    
    try {
      // Ensure logs directory exists
      execSync('mkdir -p automation/logs', { stdio: 'inherit' });
      
      // Start redundancy ecosystem
      execSync('pm2 start ecosystem-redundancy.pm2.cjs --update-env', { stdio: 'inherit' });
      
      // Wait for processes to start
      await this.sleep(3000);
      
      // Verify processes are running
      const status = execSync('pm2 status --no-daemon', { encoding: 'utf8' });
      this.status.pm2.running = true;
      this.status.pm2.processes = this.parsePM2Status(status);
      
      console.log(`âœ… PM2 Redundancy started with ${this.status.pm2.processes.length} processes`);
    } catch (error) {
      console.error('âŒ Failed to start PM2 Redundancy:', error);
      throw error;
    }
  }

  async startGitHubActionsRedundancy() {
    console.log('ðŸ™ Starting GitHub Actions Redundancy...');
    
    try {
      // Create backup workflows with different schedules
      await this.createGitHubActionsBackups();
      
      // Verify workflows exist
      this.status.github.workflows = await this.getGitHubWorkflows();
      
      console.log(`âœ… GitHub Actions Redundancy configured with ${this.status.github.workflows.length} workflows`);
    } catch (error) {
      console.error('âŒ Failed to start GitHub Actions Redundancy:', error);
      throw error;
    }
  }

  async startNetlifyFunctionsRedundancy() {
    console.log('â˜ï¸ Starting Netlify Functions Redundancy...');
    
    try {
      // Create backup function runners
      await this.createNetlifyFunctionsBackups();
      
      // Verify functions exist
      this.status.netlify.functions = await this.getNetlifyFunctions();
      
      console.log(`âœ… Netlify Functions Redundancy configured with ${this.status.netlify.functions.length} functions`);
    } catch (error) {
      console.error('âŒ Failed to start Netlify Functions Redundancy:', error);
      throw error;
    }
  }

  async createGitHubActionsBackups() {
    const workflowsDir = '.github/workflows';
    
    // Create backup workflows with different schedules
    const backupWorkflows = [
      {
        name: 'marketing-sync-backup.yml',
        schedule: '30 */12 * * *', // 30 minutes offset from primary
        jobName: 'run-marketing-sync-backup'
      },
      {
        name: 'sync-health-backup.yml',
        schedule: '*/20 * * * *', // Every 20 minutes instead of 15
        jobName: 'check-sync-backup'
      }
    ];

    for (const workflow of backupWorkflows) {
      const workflowPath = path.join(workflowsDir, workflow.name);
      if (!fs.existsSync(workflowPath)) {
        await this.createBackupWorkflow(workflow);
      }
    }
  }

  async createBackupWorkflow(workflow) {
    const template = this.getWorkflowTemplate(workflow);
    const workflowPath = path.join('.github/workflows', workflow.name);
    
    fs.writeFileSync(workflowPath, template);
    console.log(`ðŸ“ Created backup workflow: ${workflow.name}`);
  }

  getWorkflowTemplate(workflow) {
    if (workflow.name.includes('marketing-sync')) {
      return `name: Marketing Sync Backup

on:
  schedule:
    - cron: '${workflow.schedule}'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  ${workflow.jobName}:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Run marketing-sync backup
        env:
          LINKEDIN_ACCESS_TOKEN: \${{ secrets.LINKEDIN_ACCESS_TOKEN }}
          LINKEDIN_URN: \${{ secrets.LINKEDIN_URN }}
          IG_USER_ID: \${{ secrets.IG_USER_ID }}
          IG_ACCESS_TOKEN: \${{ secrets.IG_ACCESS_TOKEN }}
        run: node automation/marketing-sync.js

      - name: Commit report if changed
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          if [ -n "\$(git status --porcelain)" ]; then
            git add -A
            git commit -m "chore(marketing): update marketing-sync backup report"
            git push origin HEAD:main
          else
            echo "No changes to commit."
          fi`;
    } else {
      return `name: Sync Health Backup

on:
  schedule:
    - cron: '${workflow.schedule}'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  ${workflow.jobName}:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Run pm2-auto-sync backup (safe mode)
        env:
          AUTO_SYNC_STRATEGY: hardreset
          AUTO_SYNC_CLEAN: '0'
        run: node automation/pm2-auto-sync.js || true

      - name: Push if repository is ahead
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          # Only push if we have local commits not on origin
          AHEAD=\$(git rev-list --left-right --count HEAD...origin/main | awk '{print \$1}')
          if [ "\$AHEAD" != "0" ]; then
            git push origin HEAD:main
          else
            echo "No push needed."
          fi`;
    }
  }

  async createNetlifyFunctionsBackups() {
    const functionsDir = 'netlify/functions';
    
    // Create backup function runners for critical functions
    const criticalFunctions = [
      'netlify-auto-healer-runner',
      'continuous-orchestrator',
      'build-monitor-runner',
      'git-sync-runner'
    ];

    for (const funcName of criticalFunctions) {
      const backupName = `${funcName}-backup`;
      const backupPath = path.join(functionsDir, backupName);
      
      if (!fs.existsSync(backupPath)) {
        await this.createBackupFunction(funcName, backupName);
      }
    }
  }

  async createBackupFunction(originalName, backupName) {
    const backupDir = path.join('netlify/functions', backupName);
    const backupFile = path.join(backupDir, 'index.js');
    
    // Create directory
    fs.mkdirSync(backupDir, { recursive: true });
    
    // Create backup function
    const backupCode = `// Backup function for ${originalName}
const { execSync } = require('child_process');
const path = require('path');

exports.handler = async (event, context) => {
  try {
    console.log('Backup function ${backupName} triggered');
    
    // Execute the original function logic
    const result = await executeBackupLogic();
    
    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'Backup function executed successfully',
        originalFunction: '${originalName}',
        backupFunction: '${backupName}',
        result: result
      })
    };
  } catch (error) {
    console.error('Backup function error:', error);
    
    return {
      statusCode: 500,
      body: JSON.stringify({
        message: 'Backup function failed',
        originalFunction: '${originalName}',
        backupFunction: '${backupName}',
        error: error.message
      })
    };
  }
};

async function executeBackupLogic() {
  // Implement backup logic here
  // This could involve calling the original function or implementing alternative logic
  return { status: 'backup_executed', timestamp: new Date().toISOString() };
}`;
    
    fs.writeFileSync(backupFile, backupCode);
    console.log(`ðŸ“ Created backup function: ${backupName}`);
  }

  async getGitHubWorkflows() {
    try {
      const workflowsDir = '.github/workflows';
      if (!fs.existsSync(workflowsDir)) return [];
      
      const files = fs.readdirSync(workflowsDir);
      return files.filter(file => file.endsWith('.yml') || file.endsWith('.yaml'));
    } catch (error) {
      console.error('Error getting GitHub workflows:', error);
      return [];
    }
  }

  async getNetlifyFunctions() {
    try {
      const functionsDir = 'netlify/functions';
      if (!fs.existsSync(functionsDir)) return [];
      
      const items = fs.readdirSync(functionsDir);
      return items.filter(item => {
        const itemPath = path.join(functionsDir, item);
        return fs.statSync(itemPath).isDirectory();
      });
    } catch (error) {
      console.error('Error getting Netlify functions:', error);
      return [];
    }
  }

  parsePM2Status(statusOutput) {
    const lines = statusOutput.split('\n');
    const processes = [];
    
    for (const line of lines) {
      if (line.includes('â”‚') && !line.includes('App name')) {
        const parts = line.split('â”‚').map(p => p.trim()).filter(p => p);
        if (parts.length >= 4) {
          processes.push({
            name: parts[0],
            status: parts[1],
            cpu: parts[2],
            memory: parts[3]
          });
        }
      }
    }
    
    return processes;
  }

  startMonitoring() {
    console.log('ðŸ“Š Starting monitoring...');
    
    // Monitor every 30 seconds
    setInterval(() => {
      this.checkSystemHealth();
    }, 30000);
  }

  async checkSystemHealth() {
    try {
      // Check PM2 status
      const pm2Status = execSync('pm2 status --no-daemon', { encoding: 'utf8' });
      this.status.pm2.processes = this.parsePM2Status(pm2Status);
      
      // Check GitHub workflows
      this.status.github.workflows = await this.getGitHubWorkflows();
      
      // Check Netlify functions
      this.status.netlify.functions = await this.getNetlifyFunctions();
      
      // Log status
      console.log(`ðŸ“Š System Health - PM2: ${this.status.pm2.processes.length} processes, GitHub: ${this.status.github.workflows.length} workflows, Netlify: ${this.status.netlify.functions.length} functions`);
      
      // Check for failures and restart if needed
      await this.handleFailures();
    } catch (error) {
      console.error('Health check error:', error);
    }
  }

  async handleFailures() {
    // Check PM2 processes and restart failed ones
    const failedProcesses = this.status.pm2.processes.filter(p => p.status === 'errored' || p.status === 'stopped');
    
    for (const process of failedProcesses) {
      console.log(`ðŸ”„ Restarting failed process: ${process.name}`);
      try {
        execSync(`pm2 restart ${process.name}`, { stdio: 'inherit' });
      } catch (error) {
        console.error(`Failed to restart ${process.name}:`, error);
      }
    }
  }

  async stop() {
    console.log('ðŸ›‘ Stopping Comprehensive Redundancy System...');
    
    try {
      // Stop PM2 processes
      execSync('pm2 stop ecosystem-redundancy.pm2.cjs', { stdio: 'inherit' });
      
      console.log('âœ… Comprehensive Redundancy System stopped');
    } catch (error) {
      console.error('âŒ Error stopping system:', error);
    }
  }

  getStatus() {
    return this.status;
  }

  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// CLI interface
if (require.main === module) {
  const system = new ComprehensiveRedundancySystem();
  const command = process.argv[2] || 'start';
  
  switch (command) {
    case 'start':
      system.start();
      break;
    case 'stop':
      system.stop();
      break;
    case 'status':
      console.log(JSON.stringify(system.getStatus(), null, 2));
      break;
    default:
      console.log('Usage: node comprehensive-redundancy-system.cjs [start|stop|status]');
  }
}

module.exports = ComprehensiveRedundancySystem;