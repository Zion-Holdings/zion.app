#!/usr/bin/env node
'use strict';

const fs = require('fs');
const path = require('path');
const cron = require('node-cron');

// Import the enhanced redundancy managers
<<<<<<< HEAD
const { EnhancedPM2RedundancyManager } = require('./enhanced-pm2-redundancy-manager.cjs');
const { EnhancedGitHubActionsRedundancyManager } = require('./enhanced-github-actions-redundancy-manager.cjs');
const { EnhancedNetlifyFunctionsRedundancyManager } = require('./enhanced-netlify-functions-redundancy-manager.cjs');

class EnhancedMasterRedundancyOrchestrator {
  constructor() {
    // Use a more robust path resolution
    this.baseDir = process.cwd() || __dirname || '.';
    this.logDir = path.resolve(this.baseDir, 'automation', 'logs');
=======
const EnhancedPM2RedundancyManager = require('./enhanced-pm2-redundancy-manager.cjs');
const EnhancedGitHubActionsRedundancyManager = require('./enhanced-github-actions-redundancy-manager.cjs');
const EnhancedNetlifyFunctionsRedundancyManager = require('./enhanced-netlify-functions-redundancy-manager.cjs');

class EnhancedMasterRedundancyOrchestrator {
  constructor() {
    this.logDir = path.join(process.cwd(), 'automation', 'logs');
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
    this.ensureLogDir();
    
    // Initialize enhanced managers
    this.pm2Manager = new EnhancedPM2RedundancyManager();
    this.githubManager = new EnhancedGitHubActionsRedundancyManager();
    this.netlifyManager = new EnhancedNetlifyFunctionsRedundancyManager();
    
    this.managers = new Map([
      ['pm2', this.pm2Manager],
      ['github', this.githubManager],
      ['netlify', this.netlifyManager]
    ]);
    
    this.managerStatus = new Map();
    this.healthChecks = new Map();
    this.recoveryAttempts = new Map();
    this.systemHealth = 'healthy';
<<<<<<< HEAD
    this.startTime = new Date();
    
    // Performance metrics
    this.metrics = {
      totalHealthChecks: 0,
      successfulRecoveries: 0,
      failedRecoveries: 0,
      systemUptime: 0,
      lastFullCheck: null
    };
=======
    this.lastFullHealthCheck = null;
    this.emergencyMode = false;
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
  }

  ensureLogDir() {
    if (!fs.existsSync(this.logDir)) {
      fs.mkdirSync(this.logDir, { recursive: true });
    }
  }

  log(message, level = 'INFO') {
    const timestamp = new Date().toISOString();
<<<<<<< HEAD
    const logMessage = `[${timestamp}] [${level}] [MASTER-ORCHESTRATOR] ${message}`;
    console.log(logMessage);
    
    const logFile = path.join(this.logDir, 'master-redundancy-orchestrator.log');
    fs.appendFileSync(logFile, logMessage + '\n');
  }

  async startAllManagers() {
=======
    const logMessage = `[${timestamp}] [${level}] [ENHANCED-MASTER] ${message}`;
    console.log(logMessage);
    
    const logFile = path.join(this.logDir, 'enhanced-master-redundancy.log');
    fs.appendFileSync(logFile, logMessage + '\n');
  }

  async startAllEnhancedManagers() {
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
    this.log('Starting all enhanced redundancy managers...');
    
    const startPromises = [];
    
    for (const [name, manager] of this.managers) {
      try {
<<<<<<< HEAD
        this.log(`Starting ${name} manager...`);
        
        // Start the manager
        await manager.start();
=======
        this.log(`Starting enhanced ${name} manager...`);
        
        // Start the manager in a controlled way
        if (name === 'pm2') {
          await manager.startAllBackupProcesses();
          await manager.startHealthMonitoring();
        } else if (name === 'github') {
          await manager.createAllBackupWorkflows();
          await manager.validateBackupWorkflows();
        } else if (name === 'netlify') {
          await manager.createAllBackupFunctions();
          await manager.validateBackupFunctions();
          await manager.updateFunctionsManifest();
        }
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
        
        this.managerStatus.set(name, {
          status: 'running',
          started: new Date(),
          health: 'healthy',
<<<<<<< HEAD
          lastCheck: new Date()
        });
        
        this.log(`${name} manager started successfully`);
        
      } catch (error) {
        this.log(`Failed to start ${name} manager: ${error.message}`, 'ERROR');
=======
          type: 'enhanced'
        });
        
        this.log(`Enhanced ${name} manager started successfully`);
        
      } catch (error) {
        this.log(`Failed to start enhanced ${name} manager: ${error.message}`, 'ERROR');
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
        this.managerStatus.set(name, {
          status: 'failed',
          started: new Date(),
          health: 'unhealthy',
          error: error.message,
<<<<<<< HEAD
          lastCheck: new Date()
=======
          type: 'enhanced'
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
        });
      }
    }
    
<<<<<<< HEAD
    this.log('All managers startup completed');
  }

  async startHealthMonitoring() {
    this.log('Starting comprehensive health monitoring for all managers...');
=======
    this.log('All enhanced managers startup completed');
  }

  async startEnhancedHealthMonitoring() {
    this.log('Starting enhanced health monitoring for all managers...');
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
    
    // Monitor manager health every 2 minutes
    cron.schedule('*/2 * * * *', async () => {
      await this.checkAllManagerHealth();
    });

<<<<<<< HEAD
    // Full system health check every 15 minutes
    cron.schedule('*/15 * * * *', async () => {
      await this.fullSystemHealthCheck();
    });

    // Performance metrics collection every hour
    cron.schedule('0 * * * *', async () => {
      await this.collectPerformanceMetrics();
    });

    // System status report every 4 hours
    cron.schedule('0 */4 * * *', async () => {
      await this.generateSystemStatusReport();
=======
    // Full system health check every 30 minutes
    cron.schedule('*/30 * * * *', async () => {
      await this.fullSystemHealthCheck();
    });

    // Emergency health check every 5 minutes if in emergency mode
    cron.schedule('*/5 * * * *', async () => {
      if (this.emergencyMode) {
        await this.emergencyHealthCheck();
      }
    });

    // Comprehensive system audit every 2 hours
    cron.schedule('0 */2 * * *', async () => {
      await this.comprehensiveSystemAudit();
    });

    // Daily cleanup and maintenance
    cron.schedule('0 2 * * *', async () => {
      await this.dailyMaintenance();
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
    });
  }

  async checkAllManagerHealth() {
<<<<<<< HEAD
    this.log('Performing health check on all managers...');
    this.metrics.totalHealthChecks++;
    
    const healthPromises = [];
    
    for (const [name, manager] of this.managers) {
      try {
        const healthPromise = manager.getSystemStatus().then(status => {
          return { name, status, success: true };
        }).catch(error => {
          return { name, error: error.message, success: false };
        });
        
        healthPromises.push(healthPromise);
      } catch (error) {
        this.log(`Error initiating health check for ${name}: ${error.message}`, 'ERROR');
      }
    }
    
    // Wait for all health checks to complete
    const results = await Promise.allSettled(healthPromises);
    
    for (const result of results) {
      if (result.status === 'fulfilled') {
        const { name, status, success, error } = result.value;
        
        if (success) {
          this.managerStatus.set(name, {
            ...this.managerStatus.get(name),
            health: status.overallHealth,
            lastCheck: new Date(),
            lastStatus: status
          });
          
          this.healthChecks.set(name, status);
        } else {
          this.log(`Health check failed for ${name}: ${error}`, 'ERROR');
          this.managerStatus.set(name, {
            ...this.managerStatus.get(name),
            health: 'unhealthy',
            lastCheck: new Date(),
            error
          });
        }
      } else {
        this.log(`Health check promise rejected for manager`, 'ERROR');
      }
    }
    
    // Update overall system health
    this.updateSystemHealth();
  }

  updateSystemHealth() {
    let healthyManagers = 0;
    let totalManagers = 0;
    
    for (const [name, status] of this.managerStatus) {
      totalManagers++;
      if (status.health === 'healthy') {
        healthyManagers++;
      }
    }
    
    const healthRatio = healthyManagers / totalManagers;
    
    if (healthRatio === 1) {
      this.systemHealth = 'healthy';
    } else if (healthRatio >= 0.66) {
      this.systemHealth = 'degraded';
    } else {
      this.systemHealth = 'unhealthy';
    }
    
    this.log(`System health updated: ${this.systemHealth} (${healthyManagers}/${totalManagers} managers healthy)`);
  }

  async fullSystemHealthCheck() {
    this.log('Performing full system health check...');
    this.metrics.lastFullCheck = new Date();
    
    // Check each manager's detailed status
    for (const [name, manager] of this.managers) {
      try {
        const status = await manager.getSystemStatus();
        this.log(`${name} manager status: ${status.overallHealth}`);
        
        // Log detailed metrics if available
        if (status.recoveryStats) {
          this.log(`${name} recovery stats: ${JSON.stringify(status.recoveryStats)}`);
        }
        
        // Update metrics
        if (status.recoveryStats) {
          this.metrics.successfulRecoveries += status.recoveryStats.successfulRecoveries || 0;
          this.metrics.failedRecoveries += status.recoveryStats.failedRecoveries || 0;
        }
        
      } catch (error) {
        this.log(`Error during full health check for ${name}: ${error.message}`, 'ERROR');
      }
    }
    
    // Generate health summary
    await this.generateHealthSummary();
  }

  async generateHealthSummary() {
    const summary = {
      timestamp: new Date().toISOString(),
      systemHealth: this.systemHealth,
      uptime: Date.now() - this.startTime.getTime(),
      managers: {},
      overallMetrics: this.metrics
    };
    
    // Collect manager summaries
    for (const [name, status] of this.managerStatus) {
      summary.managers[name] = {
        status: status.status,
        health: status.health,
        uptime: status.started ? Date.now() - status.started.getTime() : 0,
        lastCheck: status.lastCheck
      };
    }
    
    // Write summary to file
    const summaryPath = path.join(this.logDir, 'health-summary.json');
    fs.writeFileSync(summaryPath, JSON.stringify(summary, null, 2));
    
    this.log('Health summary generated and saved');
  }

  async collectPerformanceMetrics() {
    this.log('Collecting performance metrics...');
    
    const metrics = {
      timestamp: new Date().toISOString(),
      systemUptime: Date.now() - this.startTime.getTime(),
      managerPerformance: {},
      systemHealth: this.systemHealth,
      totalHealthChecks: this.metrics.totalHealthChecks
    };
    
    // Collect performance data from each manager
    for (const [name, manager] of this.managers) {
      try {
        const status = await manager.getSystemStatus();
        metrics.managerPerformance[name] = {
          health: status.overallHealth,
          recoveryStats: status.recoveryStats || {},
          timestamp: new Date().toISOString()
        };
      } catch (error) {
        this.log(`Error collecting metrics for ${name}: ${error.message}`, 'ERROR');
        metrics.managerPerformance[name] = {
          error: error.message,
          timestamp: new Date().toISOString()
        };
      }
    }
    
    // Write metrics to file
    const metricsPath = path.join(this.logDir, 'performance-metrics.json');
    fs.writeFileSync(metricsPath, JSON.stringify(metrics, null, 2));
    
    this.log('Performance metrics collected and saved');
  }

  async generateSystemStatusReport() {
    this.log('Generating comprehensive system status report...');
    
    const report = {
      timestamp: new Date().toISOString(),
      systemOverview: {
        health: this.systemHealth,
        uptime: Date.now() - this.startTime.getTime(),
        totalManagers: this.managers.size,
        activeManagers: Array.from(this.managerStatus.values()).filter(s => s.status === 'running').length
      },
      managerDetails: {},
      systemMetrics: this.metrics,
      recommendations: []
    };
    
    // Collect detailed manager information
    for (const [name, status] of this.managerStatus) {
      const healthData = this.healthChecks.get(name);
      
      report.managerDetails[name] = {
        status: status.status,
        health: status.health,
        uptime: status.started ? Date.now() - status.started.getTime() : 0,
        lastCheck: status.lastCheck,
        details: healthData || null
      };
    }
    
    // Generate recommendations
    report.recommendations = this.generateRecommendations();
    
    // Write report to file
    const reportPath = path.join(this.logDir, 'system-status-report.json');
    fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));
    
    // Also create a human-readable version
    const humanReport = this.generateHumanReadableReport(report);
    const humanReportPath = path.join(this.logDir, 'system-status-report.md');
    fs.writeFileSync(humanReportPath, humanReport);
    
    this.log('System status report generated and saved');
  }

  generateRecommendations() {
    const recommendations = [];
    
    // Check for unhealthy managers
    for (const [name, status] of this.managerStatus) {
      if (status.health === 'unhealthy') {
        recommendations.push({
          priority: 'high',
          category: 'health',
          message: `Manager ${name} is unhealthy and requires immediate attention`,
          action: `Investigate and restart ${name} manager if necessary`
        });
      } else if (status.health === 'degraded') {
        recommendations.push({
          priority: 'medium',
          category: 'health',
          message: `Manager ${name} is in degraded state`,
          action: `Monitor ${name} manager closely and investigate performance issues`
        });
      }
    }
    
    // Check for high recovery attempts
    if (this.metrics.failedRecoveries > this.metrics.successfulRecoveries) {
      recommendations.push({
        priority: 'medium',
        category: 'recovery',
        message: 'System has more failed recoveries than successful ones',
        action: 'Review recovery mechanisms and improve error handling'
      });
    }
    
    // Check system uptime
    const uptimeHours = (Date.now() - this.startTime.getTime()) / (1000 * 60 * 60);
    if (uptimeHours > 24) {
      recommendations.push({
        priority: 'low',
        category: 'maintenance',
        message: 'System has been running for over 24 hours',
        action: 'Consider scheduled maintenance or restart for optimal performance'
      });
    }
    
    return recommendations;
  }

  generateHumanReadableReport(report) {
    let markdown = `# System Status Report\n\n`;
    markdown += `**Generated:** ${report.timestamp}\n`;
    markdown += `**System Health:** ${report.systemOverview.health}\n`;
    markdown += `**Uptime:** ${Math.round(report.systemOverview.uptime / (1000 * 60 * 60))} hours\n\n`;
    
    markdown += `## Manager Status\n\n`;
    for (const [name, details] of Object.entries(report.managerDetails)) {
      markdown += `### ${name}\n`;
      markdown += `- **Status:** ${details.status}\n`;
      markdown += `- **Health:** ${details.health}\n`;
      markdown += `- **Uptime:** ${Math.round(details.uptime / (1000 * 60))} minutes\n`;
      markdown += `- **Last Check:** ${details.lastCheck}\n\n`;
    }
    
    markdown += `## System Metrics\n\n`;
    markdown += `- **Total Health Checks:** ${report.systemMetrics.totalHealthChecks}\n`;
    markdown += `- **Successful Recoveries:** ${report.systemMetrics.successfulRecoveries}\n`;
    markdown += `- **Failed Recoveries:** ${report.systemMetrics.failedRecoveries}\n\n`;
    
    if (report.recommendations.length > 0) {
      markdown += `## Recommendations\n\n`;
      for (const rec of report.recommendations) {
        markdown += `### ${rec.priority.toUpperCase()} Priority\n`;
        markdown += `**${rec.message}**\n`;
        markdown += `**Action:** ${rec.action}\n\n`;
      }
    }
    
    return markdown;
  }

  async start() {
    this.log('Starting Enhanced Master Redundancy Orchestrator...');
    
    try {
      // Start all managers
      await this.startAllManagers();
      
      // Start health monitoring
      await this.startHealthMonitoring();
      
      this.log('Enhanced Master Redundancy Orchestrator started successfully');
      
      // Keep the process alive and update uptime
      setInterval(() => {
        this.metrics.systemUptime = Date.now() - this.startTime.getTime();
      }, 60000);
      
    } catch (error) {
      this.log(`Failed to start Enhanced Master Redundancy Orchestrator: ${error.message}`, 'ERROR');
      throw error;
    }
  }

  getStatus() {
    return {
      timestamp: new Date().toISOString(),
      managerStatus: Object.fromEntries(this.managerStatus),
      healthChecks: Object.fromEntries(this.healthChecks),
      automationCoverage: Object.fromEntries(this.automationCoverage),
      recoveryAttempts: Object.fromEntries(this.recoveryAttempts)
=======
  async getSystemStatus() {
    return {
      timestamp: new Date().toISOString(),
      systemHealth: this.systemHealth,
      uptime: Date.now() - this.startTime.getTime(),
      managers: Object.fromEntries(this.managerStatus),
      metrics: this.metrics
    };
  }
}

// Export for use in other modules
module.exports = { EnhancedMasterRedundancyOrchestrator };

// If run directly, start the orchestrator
if (require.main === module) {
  const orchestrator = new EnhancedMasterRedundancyOrchestrator();
  orchestrator.start().catch(error => {
    console.error('Failed to start Enhanced Master Redundancy Orchestrator:', error);
    process.exit(1);
  });
}
=======
    this.log('Checking health of all enhanced managers...');
    
    let healthyManagers = 0;
    let totalManagers = this.managers.size;
    
    for (const [name, manager] of this.managers) {
      try {
        const status = await manager.getStatus();
        const isHealthy = this.assessManagerHealth(status, name);
        
        if (isHealthy) {
          healthyManagers++;
          this.managerStatus.set(name, {
            ...this.managerStatus.get(name),
            health: 'healthy',
            lastHealthCheck: new Date(),
            status: 'running'
          });
        } else {
          this.managerStatus.set(name, {
            ...this.managerStatus.get(name),
            health: 'unhealthy',
            lastHealthCheck: new Date(),
            status: 'degraded'
          });
          
          // Trigger recovery for unhealthy managers
          await this.triggerManagerRecovery(name);
        }
        
      } catch (error) {
        this.log(`Health check failed for ${name} manager: ${error.message}`, 'ERROR');
        this.managerStatus.set(name, {
          ...this.managerStatus.get(name),
          health: 'unhealthy',
          lastHealthCheck: new Date(),
          status: 'failed',
          error: error.message
        });
      }
    }
    
    const healthPercentage = (healthyManagers / totalManagers) * 100;
    this.log(`Manager health: ${healthyManagers}/${totalManagers} (${healthPercentage.toFixed(1)}%)`);
    
    // Update system health
    if (healthPercentage >= 80) {
      this.systemHealth = 'healthy';
    } else if (healthPercentage >= 60) {
      this.systemHealth = 'degraded';
    } else {
      this.systemHealth = 'critical';
      this.emergencyMode = true;
    }
  }

  assessManagerHealth(status, managerName) {
    if (!status) return false;
    
    switch (managerName) {
      case 'pm2':
        return status.totalBackupProcesses > 0 && status.healthyProcesses > 0;
      case 'github':
        return status.totalBackupWorkflows > 0;
      case 'netlify':
        return status.totalBackupFunctions > 0;
      default:
        return true;
    }
  }

  async triggerManagerRecovery(managerName) {
    this.log(`Triggering recovery for ${managerName} manager...`);
    
    const recoveryCount = this.recoveryAttempts.get(managerName) || 0;
    if (recoveryCount >= 3) {
      this.log(`Max recovery attempts reached for ${managerName}`, 'ERROR');
      return false;
    }

    this.recoveryAttempts.set(managerName, recoveryCount + 1);
    
    try {
      const manager = this.managers.get(managerName);
      if (!manager) return false;
      
      // Attempt recovery based on manager type
      if (managerName === 'pm2') {
        await manager.startAllBackupProcesses();
      } else if (managerName === 'github') {
        await manager.createAllBackupWorkflows();
      } else if (managerName === 'netlify') {
        await manager.createAllBackupFunctions();
      }
      
      this.log(`Successfully recovered ${managerName} manager`);
      this.recoveryAttempts.set(managerName, 0); // Reset counter
      return true;
      
    } catch (error) {
      this.log(`Failed to recover ${managerName} manager: ${error.message}`, 'ERROR');
      return false;
    }
  }

  async fullSystemHealthCheck() {
    this.log('Running full enhanced system health check...');
    
    const startTime = Date.now();
    const healthReport = {
      timestamp: new Date().toISOString(),
      systemHealth: this.systemHealth,
      emergencyMode: this.emergencyMode,
      managers: {},
      overallHealth: 'unknown',
      recommendations: []
    };
    
    // Check each manager's detailed health
    for (const [name, manager] of this.managers) {
      try {
        const status = await manager.getStatus();
        healthReport.managers[name] = {
          status: this.managerStatus.get(name),
          details: status,
          health: this.assessManagerHealth(status, name) ? 'healthy' : 'unhealthy'
        };
      } catch (error) {
        healthReport.managers[name] = {
          status: this.managerStatus.get(name),
          error: error.message,
          health: 'error'
        };
      }
    }
    
    // Assess overall health
    const healthyManagers = Object.values(healthReport.managers)
      .filter(m => m.health === 'healthy').length;
    const totalManagers = Object.keys(healthReport.managers).length;
    
    if (healthyManagers === totalManagers) {
      healthReport.overallHealth = 'excellent';
    } else if (healthyManagers >= totalManagers * 0.8) {
      healthReport.overallHealth = 'good';
    } else if (healthyManagers >= totalManagers * 0.6) {
      healthReport.overallHealth = 'fair';
    } else {
      healthReport.overallHealth = 'poor';
    }
    
    // Generate recommendations
    if (healthReport.overallHealth === 'poor') {
      healthReport.recommendations.push('Immediate intervention required');
      healthReport.recommendations.push('Consider emergency recovery procedures');
    } else if (healthReport.overallHealth === 'fair') {
      healthReport.recommendations.push('Monitor closely for degradation');
      healthReport.recommendations.push('Prepare recovery procedures');
    } else if (healthReport.overallHealth === 'good') {
      healthReport.recommendations.push('Continue monitoring');
      healthReport.recommendations.push('Consider optimization opportunities');
    } else {
      healthReport.recommendations.push('System operating optimally');
      healthReport.recommendations.push('Maintain current configuration');
    }
    
    healthReport.duration = Date.now() - startTime;
    this.lastFullHealthCheck = healthReport;
    
    // Log health report
    this.log(`Full system health check completed: ${healthReport.overallHealth} (${healthReport.duration}ms)`);
    
    // Save health report
    const reportPath = path.join(this.logDir, `health-report-${Date.now()}.json`);
    fs.writeFileSync(reportPath, JSON.stringify(healthReport, null, 2));
    
    return healthReport;
  }

  async emergencyHealthCheck() {
    this.log('ðŸš¨ Running emergency health check...');
    
    // Quick emergency assessment
    const emergencyReport = {
      timestamp: new Date().toISOString(),
      type: 'emergency',
      criticalIssues: [],
      immediateActions: []
    };
    
    for (const [name, status] of this.managerStatus) {
      if (status.health === 'unhealthy' || status.status === 'failed') {
        emergencyReport.criticalIssues.push({
          manager: name,
          issue: status.error || 'Unknown issue',
          status: status.status
        });
        
        emergencyReport.immediateActions.push(`Restart ${name} manager`);
      }
    }
    
    if (emergencyReport.criticalIssues.length > 0) {
      this.log(`ðŸš¨ Critical issues detected: ${emergencyReport.criticalIssues.length}`, 'ERROR');
      
      // Take immediate action
      for (const action of emergencyReport.immediateActions) {
        this.log(`ðŸš¨ Taking immediate action: ${action}`);
        // Implement immediate recovery actions here
      }
    }
    
    return emergencyReport;
  }

  async comprehensiveSystemAudit() {
    this.log('ðŸ” Running comprehensive system audit...');
    
    const auditReport = {
      timestamp: new Date().toISOString(),
      type: 'comprehensive-audit',
      systemOverview: {},
      redundancyCoverage: {},
      recommendations: []
    };
    
    // Audit each manager's redundancy coverage
    for (const [name, manager] of this.managers) {
      try {
        const status = await manager.getStatus();
        auditReport.systemOverview[name] = status;
        
        // Assess redundancy coverage
        if (name === 'pm2') {
          const coverage = status.totalBackupProcesses / Math.max(status.totalPrimaryProcesses || 1, 1);
          auditReport.redundancyCoverage[name] = {
            coverage: coverage,
            percentage: (coverage * 100).toFixed(1) + '%',
            status: coverage >= 1 ? 'adequate' : 'insufficient'
          };
        } else if (name === 'github') {
          const coverage = status.totalBackupWorkflows / Math.max(status.totalPrimaryWorkflows || 1, 1);
          auditReport.redundancyCoverage[name] = {
            coverage: coverage,
            percentage: (coverage * 100).toFixed(1) + '%',
            status: coverage >= 1 ? 'adequate' : 'insufficient'
          };
        } else if (name === 'netlify') {
          const coverage = status.totalBackupFunctions / Math.max(status.totalPrimaryFunctions || 1, 1);
          auditReport.redundancyCoverage[name] = {
            coverage: coverage,
            percentage: (coverage * 100).toFixed(1) + '%',
            status: coverage >= 1 ? 'adequate' : 'insufficient'
          };
        }
        
      } catch (error) {
        auditReport.systemOverview[name] = { error: error.message };
      }
    }
    
    // Generate audit recommendations
    for (const [name, coverage] of Object.entries(auditReport.redundancyCoverage)) {
      if (coverage.status === 'insufficient') {
        auditReport.recommendations.push(`Increase redundancy coverage for ${name} (currently ${coverage.percentage})`);
      }
    }
    
    // Save audit report
    const reportPath = path.join(this.logDir, `audit-report-${Date.now()}.json`);
    fs.writeFileSync(reportPath, JSON.stringify(auditReport, null, 2));
    
    this.log(`ðŸ” Comprehensive system audit completed`);
    return auditReport;
  }

  async dailyMaintenance() {
    this.log('ðŸ§¹ Running daily maintenance...');
    
    try {
      // Clean up old backup files
      await this.pm2Manager.cleanupOldBackups();
      await this.githubManager.cleanupOldBackups();
      await this.netlifyManager.cleanupOldBackups();
      
      // Update manifests and configurations
      await this.netlifyManager.updateFunctionsManifest();
      
      // Generate daily summary report
      const dailyReport = {
        timestamp: new Date().toISOString(),
        type: 'daily-maintenance',
        actions: [
          'Old backup files cleaned up',
          'Manifests updated',
          'System configurations refreshed'
        ],
        status: 'completed'
      };
      
      const reportPath = path.join(this.logDir, `daily-maintenance-${Date.now()}.json`);
      fs.writeFileSync(reportPath, JSON.stringify(dailyReport, null, 2));
      
      this.log('ðŸ§¹ Daily maintenance completed successfully');
      
    } catch (error) {
      this.log(`Daily maintenance failed: ${error.message}`, 'ERROR');
    }
  }

  async getEnhancedStatus() {
    const status = {
      timestamp: new Date().toISOString(),
      systemHealth: this.systemHealth,
      emergencyMode: this.emergencyMode,
      managers: Object.fromEntries(this.managerStatus),
      lastFullHealthCheck: this.lastFullHealthCheck,
      recoveryAttempts: Object.fromEntries(this.recoveryAttempts),
      uptime: process.uptime(),
      version: '2.0.0-enhanced'
    };
    
    // Add detailed status from each manager
    for (const [name, manager] of this.managers) {
      try {
        status[`${name}Details`] = await manager.getStatus();
      } catch (error) {
        status[`${name}Details`] = { error: error.message };
      }
    }
    
    return status;
  }

  async stopAllEnhancedManagers() {
    this.log('Stopping all enhanced redundancy managers...');
    
    for (const [name, manager] of this.managers) {
      try {
        if (name === 'pm2') {
          await manager.stopAllBackupProcesses();
        }
        
        this.managerStatus.set(name, {
          ...this.managerStatus.get(name),
          status: 'stopped',
          stopped: new Date()
        });
        
        this.log(`Stopped enhanced ${name} manager`);
        
      } catch (error) {
        this.log(`Failed to stop ${name} manager: ${error.message}`, 'ERROR');
      }
    }
    
    this.log('All enhanced managers stopped');
  }

  async emergencyShutdown() {
    this.log('ðŸš¨ EMERGENCY SHUTDOWN INITIATED');
    
    try {
      // Stop all managers immediately
      await this.stopAllEnhancedManagers();
      
      // Log emergency shutdown
      const emergencyLog = {
        timestamp: new Date().toISOString(),
        type: 'emergency-shutdown',
        reason: 'Manual emergency shutdown',
        status: 'completed'
      };
      
      const logPath = path.join(this.logDir, 'emergency-shutdown.log');
      fs.appendFileSync(logPath, JSON.stringify(emergencyLog) + '\n');
      
      this.log('ðŸš¨ Emergency shutdown completed');
      
    } catch (error) {
      this.log(`Emergency shutdown failed: ${error.message}`, 'ERROR');
    }
  }

  async restartSystem() {
    this.log('ðŸ”„ Restarting enhanced redundancy system...');
    
    try {
      // Stop all managers
      await this.stopAllEnhancedManagers();
      
      // Wait a moment
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      // Start all managers again
      await this.startAllEnhancedManagers();
      
      // Restart health monitoring
      await this.startEnhancedHealthMonitoring();
      
      this.log('ðŸ”„ Enhanced redundancy system restarted successfully');
      
    } catch (error) {
      this.log(`System restart failed: ${error.message}`, 'ERROR');
    }
  }
}

module.exports = EnhancedMasterRedundancyOrchestrator;
>>>>>>> origin/cursor/automate-deployment-redundancy-and-clean-up-a700
