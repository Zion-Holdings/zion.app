{
  "timestamp": "2025-08-08T17:15:04.781Z",
  "sources": [
    {
      "name": "hn_frontpage",
      "url": "https://hnrss.org/frontpage"
    },
    {
      "name": "google_ai_blog",
      "url": "https://ai.googleblog.com/feeds/posts/default?alt=rss"
    },
    {
      "name": "huggingface_blog",
      "url": "https://huggingface.co/blog/feed.xml"
    },
    {
      "name": "openai_blog",
      "url": "https://openai.com/index.xml"
    },
    {
      "name": "arxiv_cs_ai_recent",
      "url": "https://arxiv.org/list/cs.AI/recent"
    }
  ],
  "counts": {
    "titles": 636,
    "keywords": 50,
    "themes": 23
  },
  "titles": [
    "We built an open-source asynchronous coding agent",
    "HRT's Python Fork: Leveraging PEP 690 for Faster Imports",
    "Tor: How a Military Project Became a Lifeline for Privacy",
    "GPT-5 vs. Sonnet: Complex Agentic Coding",
    "AI must RTFM: Why tech writers are becoming context curators",
    "AI is impressive because we've failed at personal computing",
    "Google's Genie is more impressive than GPT5",
    "Astronomy Photographer of the Year 2025 shortlist",
    "Getting good results from Claude code",
    "HorizonDB, a geocoding engine in Rust that replaces Elasticsearch",
    "Show HN: Synchrotron, a real-time DSP engine in pure Python",
    "Food, housing, & health care costs are a source of major stress for many people",
    "Ultrathin business card runs a fluid simulation",
    "How Attention Sinks Keep Language Models Stable",
    "Linear sent me down a local-first rabbit hole",
    "Flipper Zero dark web firmware bypasses rolling code security",
    "Cursor CLI",
    "Historical Tech Tree",
    "OpenAI's new open-source model is basically Phi-5",
    "Exit Tax: Leave Germany before your business gets big",
    "Introducing AI Sheets: a tool to work with datasets using open AI models!",
    "Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training",
    "Vision Language Model Alignment in TRL ‚ö°Ô∏è",
    "Welcome GPT OSS, the new open-source model family from OpenAI!",
    "Build an AI Shopping Assistant with Gradio MCP Servers",
    "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face",
    "Say hello to `hf`: a faster, friendlier Hugging Face CLI ‚ú®",
    "Parquet Content-Defined Chunking",
    "TimeScope: How Long Can Your Video Large Multimodal Model Go?",
    "Fast LoRA inference for Flux with Diffusers and PEFT",
    "Arc Virtual Cell Challenge: A Primer",
    "Consilium: When Multiple LLMs Collaborate",
    "Back to The Future: Evaluating AI Agents on Predicting Future Events",
    "Five Big Improvements to Gradio MCP Servers",
    "Seq vs Seq: the Ettin Suite of Paired Encoders and Decoders",
    "Migrating the Hub from Git LFS to Xet",
    "Asynchronous Robot Inference: Decoupling Action Prediction and Execution",
    "ScreenEnv: Deploy your full stack Desktop Agent",
    "Building the Hugging Face MCP Server",
    "Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders",
    "Creating custom kernels for the AMD MI300",
    "Upskill your LLMs with Gradio MCP Servers",
    "SmolLM3: smol, multilingual, long-context reasoner",
    "Three Mighty Alerts Supporting Hugging Face‚Äôs Production Infrastructure",
    "Efficient MultiModal Data Pipeline",
    "Training and Finetuning Sparse Embedding Models with Sentence Transformers v5",
    "Gemma 3n fully available in the open-source ecosystem!",
    "Transformers backend integration in SGLang",
    "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "Groq on Hugging Face Inference Providers üî•",
    "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub",
    "Featherless AI on Hugging Face Inference Providers üî•",
    "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "KV Cache from scratch in nanoVLM",
    "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "CodeAgents + Structure: A Better Way to Execute Actions",
    "üêØ Liger GRPO meets TRL",
    "Dell Enterprise Hub is all you need to build AI on premises",
    "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "Exploring Quantization Backends in Diffusers",
    "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "Microsoft and Hugging Face expand collaboration",
    "The Transformers Library: standardizing model definitions",
    "Improving Hugging Face Model Access for Kaggle Users",
    "Blazingly fast whisper transcriptions with Inference Endpoints",
    "Vision Language Models (Better, Faster, Stronger)",
    "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How?",
    "How to Build an MCP Server with Gradio",
    "Welcoming Llama Guard 4 on Hugging Face Hub",
    "The 4 Things Qwen-3's Chat Template Teaches Us",
    "Tiny Agents: a MCP-powered agent in 50 lines of code",
    "Introducing AutoRound: Intel‚Äôs Advanced Quantization for LLMs and VLMs",
    "17 Reasons Why Gradio Isn't Just Another UI Library",
    "Cohere on Hugging Face Inference Providers üî•",
    "Introducing HELMET",
    "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ",
    "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "Welcome Llama 4 Maverick & Scout on Hugging Face!",
    "Journey to 1 Million Gradio Users!",
    "The NLP Course is becoming the LLM Course!",
    "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "Accelerating LLM Inference with TGI on Intel Gaudi",
    "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "Introducing Gradio's new Dataframe!",
    "The New and Fresh analytics in Inference Endpoints",
    "Open R1: How to use OlympicCoder locally for coding?",
    "AI Policy: ü§ó Response to the White House AI Action Plan RFI",
    "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "Xet is on the Hub",
    "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "LeRobot goes to driving school: World‚Äôs largest open-source self-driving dataset",
    "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "Hugging Face and JFrog partner to make AI Security more transparent",
    "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "Trace & Evaluate your Agent with Arize Phoenix",
    "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "FastRTC: The Real-Time Communication Library for Python",
    "Remote VAEs for decoding with HF endpoints ü§ó",
    "SigLIP 2: A better multilingual vision language encoder",
    "SmolVLM2: Bringing Video Understanding to Every Device",
    "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî•",
    "Welcome Fireworks.ai on the Hub üéÜ",
    "Fixing Open LLM Leaderboard with Math-Verify",
    "1 Billion Classifications",
    "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "Build awesome datasets for video generation",
    "The Open Arabic LLM Leaderboard 2",
    "Open-source DeepResearch ‚Äì Freeing our search agents",
    "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control",
    "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "The AI tools for Art Newsletter - Issue 1",
    "How to deploy and fine-tune DeepSeek models on AWS",
    "Welcome to Inference Providers on the Hub üî•",
    "Open-R1: a fully open reproduction of DeepSeek-R1",
    "State of open video generation models in Diffusers",
    "We now support VLMs in smolagents!",
    "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models!",
    "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers",
    "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "Train 400x faster Static Embedding Models with Sentence Transformers",
    "Run ComfyUI workflows for free on Spaces",
    "AI Agents Are Here. What Now?",
    "Visual Document Retrieval Goes Multilingual",
    "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "Introducing smolagents: simple agents that write actions in code.",
    "Visualize and understand GPU memory in PyTorch",
    "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "Evaluating Audio Reasoning with Big Bench Audio",
    "Finally, a Replacement for BERT: Introducing ModernBERT",
    "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "Welcome the Falcon 3 Family of Open Models!",
    "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "Hugging Face models in Amazon Bedrock",
    "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community",
    "Welcome PaliGemma 2 ‚Äì New vision language models by Google",
    "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "Investing in Performance: Fine-tune small models with LLM insights - a CFM case study",
    "Rearchitecting Hugging Face Uploads and Downloads",
    "SmolVLM - small yet mighty Vision Language Model",
    "You could have designed state of the art positional encoding",
    "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "From Files to Chunks: Improving Hugging Face Storage Efficiency",
    "Faster Text Generation with Self-Speculative Decoding",
    "Introduction to the Open Leaderboard for Japanese LLMs",
    "Judge Arena: Benchmarking LLMs as Evaluators",
    "Open Source Developers Guide to the EU AI Act",
    "Share your open ML datasets on Hugging Face Hub!",
    "Hugging Face + PyCharm",
    "Argilla 2.4: Easily Build Fine-Tuning and Evaluation datasets on the Hub ‚Äî No Code Required",
    "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community",
    "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "Introducing SynthID Text",
    "Introducing HUGS - Scale your AI with Open Models",
    "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "Transformers.js v3: WebGPU support, new models & tasks, and more‚Ä¶",
    "üß® Diffusers welcomes Stable Diffusion 3.5 Large",
    "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "Deploying Speech-to-Speech on Hugging Face",
    "Llama 3.2 in Keras",
    "Fixing Gradient Accumulation",
    "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU",
    "A Security Review of Gradio 5",
    "Welcome, Gradio 5",
    "Scaling AI-based Data Processing with Hugging Face + Dask",
    "Faster Assisted Generation with Dynamic Speculation",
    "Improving Parquet Dedupe on Hugging Face Hub",
    "Introducing the Open FinLLM Leaderboard",
    "A Short Summary of Chinese AI Global Expansion",
    "üá®üáø BenCzechMark - Can your LLM Understand Czech?",
    "Converting Vertex-Colored Meshes to Textured Meshes",
    "Llama can now see and run on your device - welcome Llama 3.2",
    "FineVideo: behind the scenes",
    "Exploring the Daily Papers Page on Hugging Face",
    "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI",
    "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "Introducing the SQL Console on Datasets",
    "Introducing Community Tools on HuggingChat",
    "Accelerate 1.0.0",
    "Hugging Face partners with TruffleHog to Scan for Secrets",
    "Scaling robotics datasets with video encoding",
    "The 5 Most Under-Rated Tools on Hugging Face",
    "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
    "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "A failed experiment: Infini-Attention, and why we should keep trying?",
    "Introduction to ggml",
    "Welcome FalconMamba: The first strong attention-free 7B model",
    "Tool Use, Unified",
    "XetHub is joining Hugging Face!",
    "2024 Security Feature Highlights",
    "Introducing TextImage Augmentation for Document Images",
    "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "Serverless Inference with Hugging Face and NVIDIA NIMs",
    "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "WWDC 24: Running Mistral 7B with Core ML",
    "Docmatix - a huge dataset for Document Visual Question Answering",
    "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "SmolLM - blazingly fast and remarkably powerful",
    "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "How NuminaMath Won the 1st AIMO Progress Prize",
    "Announcing New Hugging Face and KerasHub integration",
    "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "Preference Optimization for Vision Language Models",
    "Google Cloud TPUs made available to Hugging Face users",
    "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "Announcing New Dataset Search Features",
    "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "Our Transformers Code Agent beats the GAIA benchmark!",
    "Welcome Gemma 2 - Google's new open LLM",
    "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "Data Is Better Together: A Look Back and Forward",
    "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "BigCodeBench: Benchmarking Large Language Models on Solving Practical and Challenging Programming Tasks",
    "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "üß® Diffusers welcomes Stable Diffusion 3",
    "Putting RL back in RLHF",
    "Making sense of this mess",
    "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "Faster assisted generation support for Intel Gaudi",
    "Space secrets security update",
    "Benchmarking Text Generation Inference",
    "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens tokens and 11 languages",
    "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "Unlocking Longer Generation with Key-Value Cache Quantization",
    "Deploy models on AWS Inferentia2 from Hugging Face",
    "Introducing Spaces Dev Mode for a seamless developer experience",
    "Build AI on premise with Dell Enterprise Hub",
    "Hugging Face on AMD Instinct MI300 GPU",
    "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model",
    "Hugging Face x LangChain : A new partner package in LangChain",
    "Introducing the Open Arabic LLM Leaderboard",
    "License to Call: Introducing Transformers Agents 2.0",
    "Subscribe to Enterprise Hub with your AWS Account",
    "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "Introducing the Open Leaderboard for Hebrew LLMs!",
    "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "Improving Prompt Consistency with Structured Generations",
    "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "Introducing the Open Chain of Thought Leaderboard",
    "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "Welcome Llama 3 - Meta's new open LLM",
    "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "AI Apps in a Flash with Gradio's Reload Mode",
    "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "Running Privacy-Preserving Inference on Hugging Face Endpoints",
    "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "Vision Language Models Explained",
    "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "CodeGemma - an official Google release for code LLMs",
    "Hugging Face partners with Wiz Research to Improve AI Security",
    "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon",
    "Public Policy at Hugging Face",
    "Bringing serverless GPU inference to Hugging Face users",
    "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "Total noob‚Äôs intro to Hugging Face Transformers",
    "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "Introducing the Chatbot Guardrails Arena",
    "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "quanto: a pytorch quantization toolkit",
    "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG",
    "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "Data is better together",
    "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator",
    "StarCoder2 and The Stack v2",
    "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "AI Watermarking 101: Tools and Techniques",
    "Fine-Tuning Gemma Models in Hugging Face",
    "Introducing the Red-Teaming Resistance Leaderboard",
    "ü™Ü Introduction to Matryoshka Embedding Models",
    "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "Welcome Gemma - Google's new open LLM",
    "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "ü§ó PEFT welcomes new merging methods",
    "Synthetic data: save money, time and carbon with open source",
    "AMD Pervasive AI Developer Contest!",
    "From OpenAI to Open LLMs with Messages API",
    "SegMoE: Segmind Mixture of Diffusion Experts",
    "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "Constitutional AI with Open LLMs",
    "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "Patch Time Series Transformer in Hugging Face",
    "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "An Introduction to AI Secure LLM Safety Leaderboard",
    "Hugging Face and Google partner for open AI collaboration",
    "Open-source LLMs as LangChain Agents",
    "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers",
    "PatchTSMixer in HuggingFace",
    "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "Faster fine-tuning using TRL & Unsloth",
    "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "LoRA training scripts of the world, unite!",
    "Speculative Decoding for 2x Faster Whisper Inference",
    "2023, year of open LLMs",
    "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "Mixture of Experts Explained",
    "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code",
    "Goodbye cold boot - how we made LoRA inference 300% faster",
    "Open LLM Leaderboard: DROP deep dive",
    "SDXL in 4 steps with Latent Consistency LoRAs",
    "Make your llama generation time fly with AWS Inferentia2",
    "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "Introducing Storage Regions on the HF Hub",
    "Personal Copilot: Train Your Own Coding Assistant",
    "Interactively explore your Huggingface dataset with one line of code",
    "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "The N Implementation Details of RLHF with PPO",
    "Exploring simple optimizations for SDXL",
    "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "Chat Templates: An End to the Silent Performance Killer",
    "Deploying the AI Comic Factory using the Inference API",
    "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "Finetune Stable Diffusion Models with DDPO via TRL",
    "Non-engineers guide: Train a LLaMA 2 chatbot",
    "Llama 2 on Amazon SageMaker a Benchmark",
    "Inference for PROs",
    "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production",
    "Introduction to 3D Gaussian Splatting",
    "Object Detection Leaderboard",
    "Optimizing your LLM in production",
    "Introducing W√ºrstchen: Fast Diffusion for Image Generation",
    "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "Overview of natively supported quantization schemes in ü§ó Transformers",
    "SafeCoder vs. Closed-source Code Assistants",
    "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "Spread Your Wings: Falcon 180B is here",
    "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "AudioLDM 2, but faster ‚ö°Ô∏è",
    "Code Llama: Llama 2 learns to code",
    "Deprecation of Git Authentication using password",
    "Making LLMs lighter with AutoGPTQ and transformers",
    "Introducing SafeCoder",
    "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model",
    "Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account",
    "Optimizing Bark using ü§ó Transformers",
    "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "Fine-tune Llama 2 with DPO",
    "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "Deploy MusicGen in no time with Inference Endpoints",
    "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "Towards Encrypted Large Language Models with FHE",
    "Practical 3D Asset Generation: A Step-by-Step Guide",
    "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "AI Policy @ü§ó: Open ML Considerations in the EU AI Act",
    "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "Results of the Open Source AI Game Jam",
    "Happy 1st anniversary ü§ó Diffusers!",
    "Llama 2 is here - get it on Hugging Face",
    "Building an AI WebTV",
    "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "Fine-tuning Stable Diffusion models on Intel CPUs",
    "Making ML-powered web games with Transformers.js",
    "Deploy LLMs with Hugging Face Inference Endpoints",
    "Making a web app generator with open ML models",
    "Leveraging Hugging Face for complex generative AI use cases",
    "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "What's going on with the Open LLM Leaderboard?",
    "Panel on Hugging Face",
    "Fine-tuning MMS Adapter Models for Multi-Lingual ASR",
    "AI Policy @ü§ó: Response to the U.S. NTIA's Request for Comment on AI Accountability",
    "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "Announcing our new Content Guidelines and Policy",
    "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "Can foundation models label data like humans?",
    "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",
    "Welcome fastText to the ü§ó Hub",
    "The Falcon has landed in the Hugging Face ecosystem",
    "AI Speech Recognition in Unity",
    "Announcing the Open Source AI Game Jam üéÆ",
    "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "Introducing BERTopic Integration with Hugging Face Hub",
    "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum",
    "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure",
    "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "Safetensors audited as really safe and becoming the default",
    "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "Large-scale Near-deduplication Behind BigCode",
    "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "Introducing RWKV ‚Äî An RNN with the advantages of a transformer",
    "Assisted Generation: a new direction toward low-latency text generation",
    "Creating a Coding Assistant with StarCoder",
    "A Dive into Text-to-Video Models",
    "StarCoder: A State-of-the-Art LLM for Code",
    "How to Install and Use the Hugging Face Unity API",
    "Running IF with üß® diffusers on a Free Tier Google Colab",
    "Training a language model with ü§ó Transformers using TensorFlow and TPUs",
    "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "How to host a Unity game in a Space",
    "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "Graph Classification with Transformers",
    "Creating Privacy Preserving AI with Substra",
    "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "Accelerating Stable Diffusion Inference on Intel CPUs",
    "Federated Learning using Hugging Face and Flower",
    "Train your ControlNet with diffusers",
    "Jupyter X Hugging Face",
    "Multivariate Probabilistic Time Series Forecasting with Informer",
    "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "New ViT and ALIGN Models From Kakao Brain",
    "Using Machine Learning to Aid Survivors and Race through Time",
    "ControlNet in Diffusers üß®",
    "Ethical guidelines for developing the Diffusers library",
    "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "Red-Teaming Large Language Models",
    "Swift Diffusers: Fast Stable Diffusion for Mac",
    "Hugging Face and AWS partner to make AI more accessible",
    "Zero-shot image-to-text generation with BLIP-2",
    "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too",
    "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware",
    "Speech Synthesis, Recognition, and More With SpeechT5",
    "Generating Stories: AI for Game Development #5",
    "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system",
    "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",
    "A Dive into Pretraining Strategies for Vision-Language Models",
    "The State of Computer Vision at Hugging Face ü§ó",
    "2D Asset Generation: AI for Game Development #4",
    "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "What Makes a Dialog Agent Useful?",
    "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "3D Asset Generation: AI for Game Development #3",
    "Universal Image Segmentation with Mask2Former and OneFormer",
    "Welcome PaddlePaddle to the Hugging Face Hub",
    "Image Similarity with Hugging Face Datasets and Transformers",
    "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "Introduction to Graph Machine Learning",
    "AI for Game Development: Creating a Farming Game in 5 Days. Part 1",
    "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",
    "Zero-shot image segmentation with CLIPSeg",
    "Model Cards: Introducing HF Model documentation tools",
    "Ethics and Society Newsletter #2: Let's talk about bias!",
    "A Complete Guide to Audio Datasets",
    "Faster Training and Inference: Habana Gaudi¬Æ2 vs Nvidia A100 80GB",
    "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "Deep Learning with Proteins",
    "Using Stable Diffusion with Core ML on Apple Silicon",
    "Probabilistic Time Series Forecasting with ü§ó Transformers",
    "VQ Diffusion with üß® Diffusers",
    "We are hiring interns!",
    "Diffusion Models Live Event",
    "Accelerating Document AI",
    "An Overview of Inference Solutions on Hugging Face",
    "Director of Machine Learning Insights [Part 4]",
    "Hugging Face Machine Learning Demos on arXiv",
    "Sentiment Classification with Fully Homomorphic Encryption using Concrete ML",
    "Generating Human-level Text with Contrastive Search in Transformers ü§ó",
    "Introducing our new pricing",
    "Training Stable Diffusion with Dreambooth using üß® Diffusers",
    "Fine-Tune Whisper with ü§ó Transformers",
    "Accelerate your models with ü§ó Optimum Intel and OpenVINO",
    "Evaluating Language Model Bias with ü§ó Evaluate",
    "From PyTorch DDP to ü§ó Accelerate to ü§ó Trainer, mastery of distributed training with ease",
    "MTEB: Massive Text Embedding Benchmark",
    "Getting started with Hugging Face Inference Endpoints",
    "Stable Diffusion in JAX/Flax üöÄ"
  ],
  "keywords": [
    {
      "word": "hugging",
      "count": 131
    },
    {
      "word": "face",
      "count": 131
    },
    {
      "word": "models",
      "count": 79
    },
    {
      "word": "transformers",
      "count": 62
    },
    {
      "word": "introducing",
      "count": 59
    },
    {
      "word": "model",
      "count": 45
    },
    {
      "word": "inference",
      "count": 45
    },
    {
      "word": "open",
      "count": 44
    },
    {
      "word": "language",
      "count": 41
    },
    {
      "word": "hub",
      "count": 31
    },
    {
      "word": "generation",
      "count": 29
    },
    {
      "word": "llms",
      "count": 25
    },
    {
      "word": "llm",
      "count": 25
    },
    {
      "word": "leaderboard",
      "count": 25
    },
    {
      "word": "learning",
      "count": 25
    },
    {
      "word": "diffusion",
      "count": 24
    },
    {
      "word": "training",
      "count": 22
    },
    {
      "word": "faster",
      "count": 21
    },
    {
      "word": "large",
      "count": 21
    },
    {
      "word": "welcome",
      "count": 20
    },
    {
      "word": "code",
      "count": 19
    },
    {
      "word": "stable",
      "count": 19
    },
    {
      "word": "intel",
      "count": 19
    },
    {
      "word": "datasets",
      "count": 18
    },
    {
      "word": "llama",
      "count": 18
    },
    {
      "word": "accelerate",
      "count": 17
    },
    {
      "word": "data",
      "count": 17
    },
    {
      "word": "vision",
      "count": 16
    },
    {
      "word": "diffusers",
      "count": 16
    },
    {
      "word": "machine",
      "count": 16
    },
    {
      "word": "gradio",
      "count": 15
    },
    {
      "word": "fine-tuning",
      "count": 15
    },
    {
      "word": "train",
      "count": 15
    },
    {
      "word": "google",
      "count": 14
    },
    {
      "word": "accelerating",
      "count": 14
    },
    {
      "word": "text",
      "count": 14
    },
    {
      "word": "deploy",
      "count": 12
    },
    {
      "word": "pytorch",
      "count": 12
    },
    {
      "word": "partner",
      "count": 12
    },
    {
      "word": "aws",
      "count": 11
    },
    {
      "word": "introduction",
      "count": 11
    },
    {
      "word": "part",
      "count": 11
    },
    {
      "word": "open-source",
      "count": 10
    },
    {
      "word": "agents",
      "count": 10
    },
    {
      "word": "embedding",
      "count": 10
    },
    {
      "word": "endpoints",
      "count": 10
    },
    {
      "word": "optimum",
      "count": 10
    },
    {
      "word": "time",
      "count": 10
    },
    {
      "word": "game",
      "count": 10
    },
    {
      "word": "agent",
      "count": 9
    }
  ],
  "themes": [
    "agent",
    "agents",
    "agentic",
    "rag",
    "retrieval",
    "evaluation",
    "guardrails",
    "mcp",
    "multimodal",
    "audio",
    "video",
    "image",
    "tools",
    "serverless",
    "edge",
    "fine-tuning",
    "distillation",
    "safety",
    "benchmark",
    "dataset",
    "open-source",
    "langchain",
    "vllm"
  ]
}