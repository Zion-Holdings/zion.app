const path = require('path');
const fs = require('fs');
const { spawnSync } = require('child_process');

function runNode(relPath, args = []) {
  const abs = path.resolve(__dirname, '..', '..', relPath);
  const res = spawnSync('node', [abs, ...args], { stdio: 'pipe', encoding: 'utf8' });
  return { status: res.status || 0, stdout: res.stdout || '', stderr: res.stderr || '' };
}

<<<<<<< HEAD
exports.config = {
  schedule: '17 */6 * * *',
};

exports.handler = async () => {
  const logs = [];
  function log(line) { logs.push(line); }
=======
function collectFiles(root, patterns) {
  const results = [];
  function walk(dir) {
    const entries = fs.readdirSync(dir, { withFileTypes: true });
    for (const e of entries) {
      const full = path.join(dir, e.name);
      if (e.isDirectory()) {
        walk(full);
      } else {
        const rel = path.relative(root, full);
        if (patterns.some((p) => rel.startsWith(p.dir) && rel.endsWith(p.ext))) {
          results.push(full);
        }
      }
    }
  }
  walk(root);
  return results;
}

function getLastModifiedIso(filePath) {
  try {
    // Prefer git last commit time if available
    const gitRes = spawnSync('git', ['log', '-1', '--format=%cI', '--', filePath], { encoding: 'utf8' });
    const out = (gitRes.stdout || '').trim();
    if (out) return out;
  } catch (e) {
    if (process.env.DEBUG) console.warn('git log failed', e);
    void e;
  }
  try {
    const stat = fs.statSync(filePath);
    return new Date(stat.mtimeMs).toISOString();
  } catch (e) {
    if (process.env.DEBUG) console.warn('stat failed', e);
    void e;
    return null;
  }
}

exports.handler = async () => {
  const logs = [];
  function log(msg) { if (msg) logs.push(String(msg)); }
>>>>>>> origin/cursor/invent-and-deploy-autonomous-cloud-automations-ef35

  // Simple stale detector: lists files not modified in > 90 days
  const cutoffDays = Number(process.env.STALE_CUTOFF_DAYS || 90);
  const cutoffMs = cutoffDays * 24 * 60 * 60 * 1000;
  const now = Date.now();

  function listFiles(dir, acc = []) {
    const entries = fs.readdirSync(dir, { withFileTypes: true });
    for (const entry of entries) {
      if (entry.name.startsWith('.git')) continue;
      const full = path.join(dir, entry.name);
      if (entry.isDirectory()) listFiles(full, acc);
      else acc.push(full);
    }
    return acc;
  }

<<<<<<< HEAD
  const roots = ['pages', 'components', 'docs'];
  const files = roots.flatMap((r) => (fs.existsSync(path.resolve(__dirname, '..', '..', r)) ? listFiles(path.resolve(__dirname, '..', '..', r)) : []));
  const stale = [];
  for (const f of files) {
    try {
      const stat = fs.statSync(f);
      const ageMs = now - stat.mtimeMs;
      if (ageMs > cutoffMs) stale.push({ path: f.replace(path.resolve(__dirname, '..', '..') + '/', ''), daysOld: Math.floor(ageMs / (24*60*60*1000)) });
    } catch {}
=======
  findings.sort((a, b) => b.ageDays - a.ageDays);

  const dataDir = path.join(root, 'data', 'reports', 'stale-content');
  const publicDir = path.join(root, 'public', 'reports', 'stale-content');
  try { fs.mkdirSync(dataDir, { recursive: true }); } catch (err) { void err; }
  try { fs.mkdirSync(publicDir, { recursive: true }); } catch (err) { void err; }

  const json = {
    generatedAt: new Date().toISOString(),
    totals: {
      count: findings.length,
      byGroup: findings.reduce((acc, f) => { acc[f.group] = (acc[f.group] || 0) + 1; return acc; }, {})
    },
    thresholds,
    findings,
  };
  const jsonPath = path.join(dataDir, `stale-content-${new Date().toISOString().replace(/[:.]/g, '-')}.json`);
  fs.writeFileSync(jsonPath, JSON.stringify(json, null, 2));

  const latestPublic = path.join(publicDir, 'latest.json');
  fs.writeFileSync(latestPublic, JSON.stringify(json, null, 2));

  const mdPath = path.join(root, 'docs', 'reports', 'stale-content.md');
  try { fs.mkdirSync(path.dirname(mdPath), { recursive: true }); } catch (err) { void err; }
  const md = [
    '# Stale Content Report',
    '',
    `Generated: ${json.generatedAt}`,
    '',
    `Total stale items: ${json.totals.count}`,
    '',
    '| Group | Count |',
    '|-------|------:|',
    ...Object.entries(json.totals.byGroup).map(([k,v]) => `| ${k} | ${v} |`),
    '',
    '| File | Last Modified | Age (days) | Threshold |',
    '|------|---------------|-----------:|----------:|',
    ...findings.map(f => `| ${f.file} | ${f.lastModified} | ${f.ageDays} | ${f.thresholdDays} |`),
    '',
    `Public JSON: /reports/stale-content/latest.json`,
  ].join('\n');
  fs.writeFileSync(mdPath, md);

  log(`Wrote stale content report: ${jsonPath}`);
  log(`Updated public: ${latestPublic}`);

  // Commit and push changes
  try {
    const sync = runNode('automation/advanced-git-sync.cjs');
    log(sync.stdout || '');
    if (sync.stderr) log(sync.stderr);
  } catch (e) {
    log(`git sync error: ${e.message}`);
>>>>>>> origin/cursor/invent-and-deploy-autonomous-cloud-automations-ef35
  }

  const reportDir = path.resolve(__dirname, '..', '..', 'public', 'automation');
  fs.mkdirSync(reportDir, { recursive: true });
  const reportPath = path.join(reportDir, 'stale-content-report.json');
  fs.writeFileSync(reportPath, JSON.stringify({ generatedAt: new Date().toISOString(), cutoffDays, total: stale.length, stale }, null, 2));
  log(`Saved report to ${reportPath}`);

  // Optional: also run existing scanners
  runNode('automation/todo-scanner.cjs');

  // Commit and push via advanced git sync
  runNode('automation/advanced-git-sync.cjs');

  return { statusCode: 200, headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ ok: true, total: stale.length }) };
};
